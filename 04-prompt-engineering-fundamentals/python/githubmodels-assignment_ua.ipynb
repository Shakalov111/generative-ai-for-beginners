{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374357bb",
   "metadata": {},
   "source": [
    "# Вступ до інженерії промптів\n",
    "Інженерія промптів - це процес розробки та оптимізації промптів для завдань обробки природної мови. Він включає вибір правильних промптів, налаштування їхніх параметрів та оцінку їх ефективності. Інженерія промптів є критично важливою для досягнення високої точності та ефективності в моделях NLP. У цьому розділі ми дослідимо основи інженерії промптів, використовуючи моделі OpenAI для експериментів."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e39f41",
   "metadata": {},
   "source": [
    "### Вправа 1: Токенізація\n",
    "Дослідіть токенізацію за допомогою tiktoken - швидкого токенізатора з відкритим кодом від OpenAI\n",
    "Дивіться [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) для додаткових прикладів.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e862bdaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ВПРАВА:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1. Спочатку запустіть вправу як є\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2. Змініть текст на будь-який промпт, який ви хочете використати, і перезапустіть, щоб побачити токени\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Визначте промпт, який ви хочете токенізувати\u001b[39;00m\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mЮпітер - п\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mята планета від Сонця і найбільша \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mв Сонячній системі. Це газовий гігант з масою \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mприродним об\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mєктом на нічному небі після Місяця та Венери.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "# ВПРАВА:\n",
    "# 1. Спочатку запустіть вправу як є\n",
    "# 2. Змініть текст на будь-який промпт, який ви хочете використати, і перезапустіть, щоб побачити токени\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Визначте промпт, який ви хочете токенізувати\n",
    "text = f\"\"\"\n",
    "Юпітер - п'ята планета від Сонця і найбільша \\\n",
    "в Сонячній системі. Це газовий гігант з масою \\\n",
    "в одну тисячну від маси Сонця, але в два з половиною \\\n",
    "рази більшою за масу всіх інших планет Сонячної системи разом узятих. \\\n",
    "Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком \\\n",
    "на нічному небі, і був відомий стародавнім цивілізаціям ще \\\n",
    "до писаної історії. Він названий на честь римського бога Юпітера.[19] \\\n",
    "При спостереженні з Землі Юпітер може бути настільки яскравим, що його відбите \\\n",
    "світло може відкидати видимі тіні,[20] і в середньому він є третім за яскравістю \\\n",
    "природним об'єктом на нічному небі після Місяця та Венери.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06898da1",
   "metadata": {},
   "source": [
    "### Вправа 2: Перевірка налаштування ключа Github Models\n",
    "\n",
    "Запустіть код нижче, щоб перевірити, чи правильно налаштована кінцева точка Github Models. Код просто випробовує простий базовий промпт і перевіряє завершення. Вхідний текст `о скажи, чи бачиш ти` має завершитись відповідно до контексту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2280e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Це початок відомої української пісні «Дивлюсь я на небо», слова якої написав Михайло Петренко. Ось як продовжується:\n",
      "\n",
      "```\n",
      "О, скажи, чи бачиш ти\n",
      "Щиру правду у мей зорі?\n",
      "Чи навіє вони мені –\n",
      "Слів, яко небі ясні.\n",
      "```\n",
      "Кажіть продовжити?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, client, model_name, temperature=1.0, max_tokens=1000, top_p=1.0):\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Ви - корисний асистент.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Виклик допоміжного методу\n",
    "\n",
    "### 1. Встановіть основний вміст або текст промпту\n",
    "text = f\"\"\"\n",
    "о скажи, чи бачиш ти\n",
    "\"\"\"\n",
    "\n",
    "### 2. Використайте його в шаблоні промпту нижче\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Запустіть промпт\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a442c88",
   "metadata": {},
   "source": [
    "### Вправа 3: Вигадки\n",
    "Дослідіть, що відбувається, коли ви просите LLM повернути завершення для промпту про тему, яка може не існувати, або про теми, про які вона може не знати, оскільки вони були за межами її попередньо навченого набору даних (більш пізні). Подивіться, як змінюється відповідь, якщо ви спробуєте інший промпт або іншу модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Встановіть текст для простого промпту або основного вмісту\n",
    "## Промпт показує формат шаблону з текстом - додайте підказки, команди тощо, якщо потрібно\n",
    "## Запустіть завершення\n",
    "text = f\"\"\"\n",
    "створіть план уроку про Марсіанську війну 2076 року.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d0b91",
   "metadata": {},
   "source": [
    "### Вправа 4: На основі інструкцій\n",
    "Використовуйте змінну \"text\" для встановлення основного вмісту\n",
    "та змінну \"prompt\" для надання інструкції, пов'язаної з цим основним вмістом.\n",
    "\n",
    "Тут ми просимо модель підсумувати текст для учня другого класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defed9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовий приклад\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Приклад тексту\n",
    "text = f\"\"\"\n",
    "Юпітер - п'ята планета від Сонця і найбільша \\\n",
    "в Сонячній системі. Це газовий гігант з масою \\\n",
    "в одну тисячну від маси Сонця, але в два з половиною \\\n",
    "рази більшою за масу всіх інших планет Сонячної системи разом узятих. \\\n",
    "Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком \\\n",
    "на нічному небі, і був відомий стародавнім цивілізаціям ще \\\n",
    "до писаної історії. Він названий на честь римського бога Юпітера.[19] \\\n",
    "При спостереженні з Землі Юпітер може бути настільки яскравим, що його відбите \\\n",
    "світло може відкидати видимі тіні,[20] і в середньому він є третім за яскравістю \\\n",
    "природним об'єктом на нічному небі після Місяця та Венери.\n",
    "\"\"\"\n",
    "\n",
    "## Встановіть промпт\n",
    "prompt = f\"\"\"\n",
    "Підсумуйте наданий вам контент для учня другого класу.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Запустіть промпт\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fb6a1",
   "metadata": {},
   "source": [
    "### Вправа 5: Складний промпт\n",
    "Спробуйте запит, який має системні повідомлення, повідомлення користувача та асистента\n",
    "Система встановлює контекст асистента\n",
    "Повідомлення користувача і асистента забезпечують контекст багатокрокової розмови\n",
    "\n",
    "Зверніть увагу, як особистість асистента встановлена як \"саркастична\" в системному контексті.\n",
    "Спробуйте використати інший контекст особистості. Або спробуйте іншу серію повідомлень вводу/виводу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.complete(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Ви - саркастичний асистент.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Хто виграв чемпіонат світу в 2020 році?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Як ви думаєте, хто виграв? Los Angeles Dodgers, звичайно.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Де це відбувалося?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f205c5",
   "metadata": {},
   "source": [
    "### Вправа: Дослідіть свою інтуїцію\n",
    "Наведені вище приклади дають вам шаблони, які ви можете використовувати для створення нових промптів (простих, складних, інструкційних тощо) - спробуйте створити інші вправи для дослідження деяких інших ідей, про які ми говорили, таких як приклади, підказки та інше."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
